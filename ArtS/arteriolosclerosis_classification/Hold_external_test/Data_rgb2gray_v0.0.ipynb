{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGELOG\n",
    "\n",
    "v0.0\n",
    "- initiate from segmentation version 0.2 and classificaiton augmentor 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2024-04-03 03:56:19 ] CUDA_VISIBLE_DEVICES automatically set to: 1           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()\n",
    "\n",
    "import glob, numpy as np, tensorflow as tf, skimage.io, os, time, cv2\n",
    "from tensorflow.keras import layers\n",
    "from histomicstk.preprocessing.augmentation import rgb_perturb_stain_concentration\n",
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "import sys  \n",
    "sys.path.append('/home/jjlou/Jerry/jerry_packages')\n",
    "from jerry_utils import restart_kernel, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/jjlou/Jerry/wsi-arterio/arteriosclerotic_vessel_detection_and_fine_segmentation/Arteriolosclerosis_classification/data_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random flip, translation, and rotation via tensorflow layers\n",
    "def aug(images, labels):\n",
    "    \n",
    "    augment = tf.keras.Sequential([\n",
    "        layers.RandomTranslation(0.05, 0.05),\n",
    "        layers.RandomRotation(1),\n",
    "        layers.RandomFlip(),\n",
    "    ])\n",
    "       \n",
    "    images = tf.cast(images, 'uint8')\n",
    "      \n",
    "    images = augment(images)  \n",
    "    \n",
    "    return tf.cast(images, 'uint8'), tf.cast(labels, 'uint8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_rgb2gray(image, mask):\n",
    "    image = np.reshape(image, (512,512,3))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    image = tf.stack([image, image, image], -1)\n",
    "    return tf.cast(image, 'uint8'), tf.cast(mask, 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.numpy_function creates output with unknown shape.. so need to reshape it\n",
    "def reshape(image, labels):\n",
    "    image = tf.reshape(image, [512,512,3])\n",
    "    labels = tf.reshape(labels, [1,])\n",
    "    return tf.cast(image, 'uint8'), tf.cast(labels, 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save = f'{root}/Train_Gray.BasicMorph.Aug_x19'\n",
    "train_shards_load_pos = sorted(glob.glob(f'{root}/train/pos/*'))    \n",
    "train_shards_load_neg = sorted(glob.glob(f'{root}/train/neg/*'))\n",
    "\n",
    "train_shard_num_pos = len(train_shards_load_pos)\n",
    "train_shard_num_neg = len(train_shards_load_neg)\n",
    "\n",
    "# Augment Train Pos\n",
    "# repeat 19 times since average pos/neg patch ratio is 19 and we well repeat neg shards x2\n",
    "if not glob.glob(f'{train_save}/pos_shard_{train_shard_num_pos-1}/*/*/*.snapshot'):\n",
    "    for s in train_shards_load_pos:\n",
    "        shard_save = f'{train_save}/pos_shard_{train_shards_load_pos.index(s)}'\n",
    "        if not glob.glob(f'{shard_save}/*/*/*.snapshot'):\n",
    "            assert not glob.glob(f'{shard_save}/*/*.shard'), f'{shard_save} did not save properly'\n",
    "            shard = tf.data.Dataset.load(s)\n",
    "            shard = (\n",
    "                shard.shuffle(len(shard), reshuffle_each_iteration=True)\n",
    "                .repeat(19)\n",
    "                .map(lambda i,m: tf.numpy_function(aug_rgb2gray, [i,m], [tf.uint8, tf.uint8]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .map(lambda i,m: aug(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .batch(1)\n",
    "            ) \n",
    "            shard.save(shard_save)\n",
    "            restart_kernel()\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# Augment Train Neg\n",
    "if not glob.glob(f'{train_save}/neg_shard_{train_shard_num_neg-1}/*/*/*.snapshot'):\n",
    "    for s in train_shards_load_neg:\n",
    "        shard_save = f'{train_save}/neg_shard_{train_shards_load_neg.index(s)}'\n",
    "        if not glob.glob(f'{shard_save}/*/*/*.snapshot'):\n",
    "            assert not glob.glob(f'{shard_save}/*/*.shard'), f'{shard_save} did not save properly'\n",
    "            shard = tf.data.Dataset.load(s)\n",
    "            shard = (\n",
    "                shard.shuffle(len(shard), reshuffle_each_iteration=True)\n",
    "                .map(lambda i,m: tf.numpy_function(aug_rgb2gray, [i,m], [tf.uint8, tf.uint8]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .map(lambda i,m: aug(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .batch(1)\n",
    "            ) \n",
    "            shard.save(shard_save)\n",
    "            restart_kernel()\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
