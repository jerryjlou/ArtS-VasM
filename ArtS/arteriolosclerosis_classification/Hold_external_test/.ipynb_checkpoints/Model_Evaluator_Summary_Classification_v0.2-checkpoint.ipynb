{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGELOG\n",
    "\n",
    "v0.1\n",
    "- hold out and external testing\n",
    "\n",
    "v0.0 11/9/2023\n",
    "- initialize a dataframe for all the metrics\n",
    "For each K:\n",
    "    - load train npz and unravel true and pred\n",
    "    - use true and pred to calculate all the metrics\n",
    "    - save the metrics into central dataframe\n",
    "    - do the same for valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2024-01-10 10:55:17 ] CUDA_VISIBLE_DEVICES automatically set to: 1           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()\n",
    "\n",
    "import numpy as np, pandas as pd, tensorflow as tf, os, time\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output, HTML, Javascript, display\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "\n",
    "import sys  \n",
    "sys.path.append('/home/jjlou/Jerry/jerry_packages')\n",
    "from jerry_utils import restart_kernel\n",
    "import jerry_losses, jerry_metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Unfrozen_EfficientNetV2L_v0.65'\n",
    "root = '/home/jjlou/Jerry/wsi-arterio/arteriosclerotic_vessel_detection_and_fine_segmentation/Arteriolosclerosis_classification/data_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(index=range(2))\n",
    "\n",
    "df_model['Hold confusion matrix'] = ''\n",
    "df_model['Hold false pos rate'] = ''\n",
    "df_model['Hold false neg rate'] = ''          \n",
    "df_model['Hold specificity'] = ''\n",
    "df_model['Hold recall'] = ''\n",
    "df_model['Hold precision'] = ''\n",
    "df_model['Hold accuracy'] = ''\n",
    "df_model['Hold F1'] = ''\n",
    "df_model['Hold ROC AUC'] = ''\n",
    "df_model['Hold PR AUC'] = ''\n",
    "\n",
    "df_model['External confusion matrix'] = ''\n",
    "df_model['External false pos rate'] = ''\n",
    "df_model['External false neg rate'] = ''          \n",
    "df_model['External specificity'] = ''\n",
    "df_model['External recall'] = ''\n",
    "df_model['External precision'] = ''\n",
    "df_model['External accuracy'] = ''\n",
    "df_model['External F1'] = ''\n",
    "df_model['External ROC AUC'] = ''\n",
    "df_model['External PR AUC'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'{root}/models_raw/{name}.hdf5'\n",
    "load_path = f'{root}/models_raw/{name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = np.load(f'{load_path}_hold.npz')\n",
    "pred = hold['pred']\n",
    "true = hold['true']\n",
    "\n",
    "#hold\n",
    "tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "df_model['Hold confusion matrix'] = confusion_matrix(true, pred)\n",
    "df_model['Hold false pos rate'] = fp / (fp + tn)\n",
    "df_model['Hold false neg rate'] = fn / (tp + fn)           \n",
    "df_model['Hold specificity'] = tn / (tn + fp)\n",
    "df_model['Hold recall'] = recall_score(true, pred)\n",
    "df_model['Hold precision'] = precision_score(true, pred)\n",
    "df_model['Hold accuracy'] = accuracy_score(true, pred)\n",
    "df_model['Hold F1'] = f1_score(true, pred)\n",
    "df_model['Hold ROC AUC'] = roc_auc_score(true, pred)\n",
    "df_model['Hold PR AUC'] = average_precision_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "external = np.load(f'{load_path}_external.npz')\n",
    "pred = external['pred']\n",
    "true = external['true']\n",
    "\n",
    "#external\n",
    "tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "df_model['External confusion matrix'] = confusion_matrix(true, pred)\n",
    "df_model['External false pos rate'] = fp / (fp + tn)\n",
    "df_model['External false neg rate'] = fn / (tp + fn)           \n",
    "df_model['External specificity'] = tn / (tn + fp)\n",
    "df_model['External recall'] = recall_score(true, pred)\n",
    "df_model['External precision'] = precision_score(true, pred)\n",
    "df_model['External accuracy'] = accuracy_score(true, pred)\n",
    "df_model['External F1'] = f1_score(true, pred)\n",
    "df_model['External ROC AUC'] = roc_auc_score(true, pred)\n",
    "df_model['External PR AUC'] = average_precision_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "df_model['Trainable Params'] = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "\n",
    "df_model.to_csv(f'{root}/models_results/{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
