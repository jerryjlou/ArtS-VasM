{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGELOG\n",
    "\n",
    "v0.9\n",
    "- hold out and external testing\n",
    "- check for white out after color augmentation. If yes, only basic morph aug.\n",
    "- shard each i,m pair into it's one individual dataset object\n",
    "\n",
    "v0.8 11/24/2023\n",
    "- for hold out and external testing\n",
    "\n",
    "v0.7 11/1/2023\n",
    "- divide train into pos and neg masks\n",
    "- repeat pos x5 because there are about x5 neg compared to pos dats/mask pairs\n",
    "\n",
    "v0.6 10/9/2023\n",
    "- change to segmentation mask only\n",
    "- load each shard one by one, augment, then save\n",
    "\n",
    "v0.5\n",
    "- revise v0.4 to version for vessel detection and rough segmentation\n",
    "\n",
    "v0.4\n",
    "- initiate version for arteriolosclerotic vessel classification and fine segmentation\n",
    "\n",
    "v0.3\n",
    "    augment = tf.keras.Sequential([\n",
    "        layers.RandomTranslation(0.08, 0.08, fill_mode='wrap'),\n",
    "        layers.RandomRotation(1, fill_mode='wrap'),\n",
    "        layers.RandomFlip(),\n",
    "    ])\n",
    "    \n",
    "    image = rgb_perturb_stain_concentration(image, sigma1=0.58, sigma2=0.27)\n",
    "\n",
    "v0.2\n",
    "- rolling color augmentation into tf.data.Dataset.map.. this seems to resolve memory issue\n",
    "\n",
    "v0.1 6/29/2023\n",
    "- add in color augmentation\n",
    "- add in restart run all function to refresh memory each loop\n",
    "\n",
    "v0.0 6/16/23:\n",
    "- no color augmentation\n",
    "- no stain normalization\n",
    "\n",
    "Pseudocode Outline\n",
    "\n",
    "Create list of folder names in wsi-arterio_batches_all/data\n",
    "Loop through list of folder names\n",
    "    Load train dats and msk\n",
    "    Load valid dats and msk\n",
    "    Augment train dats and msk tf dataset\n",
    "    Convert valid dats and msk to tf dataset\n",
    "    Save train and valid into the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2024-01-22 08:43:35 ] CUDA_VISIBLE_DEVICES automatically set to: 2           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()\n",
    "\n",
    "import glob, numpy as np, tensorflow as tf, time\n",
    "from tensorflow.keras import layers\n",
    "from histomicstk.preprocessing.augmentation import rgb_perturb_stain_concentration\n",
    "\n",
    "import sys  \n",
    "sys.path.append('/home/jjlou/Jerry/jerry_packages')\n",
    "from jerry_utils import restart_kernel, shard_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/jjlou/Jerry/wsi-arterio/vessel_detection_and_rough_segmentation/data_test'\n",
    "repeats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random flip via tensorflow layers\n",
    "def aug(images, mask):\n",
    "    \n",
    "    augment = tf.keras.Sequential([\n",
    "        layers.RandomTranslation(0.05, 0.05),\n",
    "        layers.RandomRotation(1),\n",
    "        layers.RandomFlip(),\n",
    "    ])\n",
    "       \n",
    "    images = tf.cast(images, 'uint8')\n",
    "    mask = tf.cast(mask, 'uint8') \n",
    "    \n",
    "    mask = tf.stack([mask, mask, mask], -1)\n",
    "    \n",
    "    images_mask = tf.concat([images, mask], -1)  \n",
    "    images_mask = augment(images_mask)  \n",
    "    \n",
    "    image = images_mask[:,:,:3]\n",
    "    mask = images_mask[:,:,3]\n",
    "    mask = tf.expand_dims(mask,axis=2)\n",
    "    \n",
    "    return tf.cast(image, 'uint8'), tf.cast(mask, 'uint8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_aug(image, mask): \n",
    "    image = rgb_perturb_stain_concentration(image, sigma1=0.43, sigma2=0.17)\n",
    "    return tf.cast(image, 'uint8'), tf.cast(mask, 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.numpy_function creates output with unknown shape.. so need to reshape it\n",
    "def reshape(image, mask):\n",
    "    image = tf.reshape(image, [512,512,3])\n",
    "    mask = tf.reshape(mask, [512,512])\n",
    "    return tf.cast(image, 'uint8'), tf.cast(mask, 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = sorted(glob.glob(f'{root}/train_Basic.Aug/*/*'))\n",
    "save = f'{root}/train_Color.Basic.Aug_x{repeats}_sharded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in load:\n",
    "    ID = s.split('/')[-2]\n",
    "    num_shard = s.split('/')[-1]\n",
    "    instance_num = 0\n",
    "    block = tf.data.Dataset.load(s)\n",
    "    block_length = len(block)\n",
    "    if not glob.glob(f'{save}/{ID}/{num_shard}_instance.{block_length-1}/shard_{repeats-1}'):\n",
    "        for i, l in block:\n",
    "            shard_save = f'{save}/{ID}/{num_shard}_instance.{instance_num}'\n",
    "            if not glob.glob(f'{shard_save}/shard_{repeats-1}/*/*/*.snapshot'):\n",
    "                shard = tf.data.Dataset.from_tensors((i,l))\n",
    "                shard = shard.repeat(repeats)\n",
    "                test = tf.data.Dataset.from_tensors((i,l))\n",
    "                test = (\n",
    "                    test.map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .map(lambda i,m: tf.numpy_function(color_aug, [i,m], [tf.uint8, tf.uint8]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                )\n",
    "                try:\n",
    "                    for a,b in test:\n",
    "                        rgb_mean = tf.math.reduce_mean(a)\n",
    "                except:\n",
    "                        shard = (\n",
    "                            shard.map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                            .map(lambda i,m: aug(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                            .batch(1)\n",
    "                        )\n",
    "                        shard_dataset(shard, shard_save)\n",
    "                        instance_num += 1\n",
    "                        continue\n",
    "                if (rgb_mean > 210) or (rgb_mean < 65) or (rgb_mean == None):\n",
    "                    shard = (\n",
    "                        shard.map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .map(lambda i,m: aug(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .batch(1)\n",
    "                    )\n",
    "                    shard_dataset(shard, shard_save)\n",
    "                else:\n",
    "                    shard = (\n",
    "                        shard.map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .map(lambda i,m: tf.numpy_function(color_aug, [i,m], [tf.uint8, tf.uint8]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .map(lambda i,m: aug(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .batch(1)\n",
    "                    )\n",
    "                    shard_dataset(shard, shard_save)\n",
    "                instance_num += 1\n",
    "            else:\n",
    "                instance_num += 1\n",
    "        restart_kernel()\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
