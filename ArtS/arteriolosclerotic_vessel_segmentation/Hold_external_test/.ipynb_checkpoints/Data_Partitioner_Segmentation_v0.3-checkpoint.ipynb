{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGELOG\n",
    "\n",
    "v0.3\n",
    "- load and save each image mask pair individually\n",
    "\n",
    "v0.2 11/15/2023\n",
    "- hold out and external testing\n",
    "\n",
    "v0.1 11/13/2023\n",
    "- Divide into Training and Hold out only\n",
    "\n",
    "v0.0 7/14/2023\n",
    "- initiate from the wsi-arterio_batches_all_classification Data_Partitioner_v0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2023-11-26 14:55:07 ] CUDA_VISIBLE_DEVICES automatically set to: 3           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()\n",
    "\n",
    "import glob, numpy as np, pandas as pd, tensorflow as tf, matplotlib.pyplot as plt, os, time\n",
    "\n",
    "# import after setting OPENCV_IO_MAX_IMAGE_PIXELS to 2^50\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,50).__str__() \n",
    "import cv2\n",
    "\n",
    "import sys  \n",
    "sys.path.append('/home/jjlou/Jerry/jerry_packages')\n",
    "from jerry_utils import restart_kernel, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/jjlou/Jerry/wsi-arterio/arteriosclerotic_vessel_detection_and_fine_segmentation/Vessel_WallsLumen_Segmentation/data_test_v2'\n",
    "shape = (512, 512) # resize all images to this shape\n",
    "\n",
    "hold_out_list = ['UCI-37-18', 'D-492']\n",
    "external_list = ['V019-B1_VP', 'V019_B3_VP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dats=None, msk=None, shape=shape):\n",
    "    image = tf.cast(cv2.resize(cv2.imread(dats), shape), dtype='uint8')\n",
    "    \n",
    "    LMask = []\n",
    "    Mask = []\n",
    "    for m in msk:\n",
    "        msk_loaded = cv2.resize(cv2.imread(m), shape)\n",
    "        msk_loaded = msk_loaded[:,:,0]\n",
    "        msk_loaded = msk_loaded > 0\n",
    "        msk_loaded = msk_loaded.astype(float)\n",
    "        find_L = m.find('L')\n",
    "        if find_L != -1:\n",
    "            LMask.append(msk_loaded)\n",
    "        elif find_L == -1:\n",
    "            Mask.append(msk_loaded)\n",
    "    \n",
    "    mask = Mask[0] + LMask[0]\n",
    "    mask = tf.cast(mask, dtype='uint8')\n",
    "    \n",
    "    return tf.data.Dataset.from_tensors((image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dats=None, msk=None, path_root=None, path_modifier='', shape=shape):\n",
    "    for i in range(len(dats)):\n",
    "        shard_dat = dats[i]\n",
    "        shard_msk = msk[i*2:i*2+2]\n",
    "        folder = shard_dat.split('/')[-2]\n",
    "        ID = shard_dat.split('/')[-1].split('.')[-2]\n",
    "        save_path = f'{path_root}/{folder}/{ID}'\n",
    "        if not glob.glob(f'{save_path}/*/*/*.snapshot'):\n",
    "            assert not glob.glob(f'{save_path}/*/*.shard'), f'{save_path} did not save properly'\n",
    "            shard = load_data(dats=shard_dat, msk=shard_msk)\n",
    "            shard.save(save_path)            \n",
    "            #restart_kernel()\n",
    "            #time.sleep(10)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all patches (dats) and list of all masks (msk)\n",
    "dats_pos_batches1and2 = sorted(glob.glob('/data/raw/wsi_arterio_2nd_alg/data/pos/*/*'))\n",
    "dats_pos_batch3 = sorted(glob.glob('/data/raw/wsi_arterio_2nd_alg/batch_3_data/annotations/pos/*/*'))\n",
    "dats_pos = dats_pos_batches1and2 + dats_pos_batch3\n",
    "\n",
    "msk_batches1and2 = sorted(glob.glob('/data/raw/wsi_arterio_2nd_alg/data/msk/*/*'))\n",
    "msk_batch3 = sorted(glob.glob('/data/raw/wsi_arterio_2nd_alg/batch_3_data/annotations/msk/*/*'))\n",
    "msk_pos = msk_batches1and2 + msk_batch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_dats_pos = []\n",
    "hold_out_msk_pos = []\n",
    "\n",
    "# Find all instances of the hold out patient IDs in dats and msk then save in corresponding list\n",
    "for h in hold_out_list:\n",
    "    for d in dats_pos:\n",
    "        if d.find(h) != -1:\n",
    "            hold_out_dats_pos.append(d)\n",
    "        else:\n",
    "            continue\n",
    "    for m in msk_pos:\n",
    "        if m.find(h) != -1:\n",
    "            hold_out_msk_pos.append(m)\n",
    "        else:\n",
    "            continue   \n",
    "            \n",
    "hold_path = f'{root}/hold'\n",
    "if len(glob.glob(f'{hold_path}/*/*')) < len(hold_out_dats_pos):\n",
    "    process_data(\n",
    "        dats=hold_out_dats_pos, \n",
    "        msk=hold_out_msk_pos,   \n",
    "        path_root=hold_path, \n",
    "        path_modifier='')\n",
    "\n",
    "# Remove hold out dats and msks from original list\n",
    "for d in hold_out_dats_pos:\n",
    "    dats_pos.remove(d)\n",
    "for m in hold_out_msk_pos:\n",
    "    msk_pos.remove(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dats_pos = []\n",
    "external_msk_pos = []\n",
    "\n",
    "# Find all instances of the hold out patient IDs in dats and msk then save in corresponding list\n",
    "for h in external_list:\n",
    "    for d in dats_pos:\n",
    "        if d.find(h) != -1:\n",
    "            external_dats_pos.append(d)\n",
    "        else:\n",
    "            continue\n",
    "    for m in msk_pos:\n",
    "        if m.find(h) != -1:\n",
    "            external_msk_pos.append(m)\n",
    "        else:\n",
    "            continue   \n",
    "            \n",
    "external_path = f'{root}/external'\n",
    "if len(glob.glob(f'{external_path}/*/*')) < len(external_dats_pos):\n",
    "    process_data(\n",
    "        dats=external_dats_pos, \n",
    "        msk=external_msk_pos,   \n",
    "        path_root=external_path, \n",
    "        path_modifier='')\n",
    "\n",
    "# Remove hold out dats and msks from original list\n",
    "for d in external_dats_pos:\n",
    "    dats_pos.remove(d)\n",
    "for m in external_msk_pos:\n",
    "    msk_pos.remove(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f'{root}/train'\n",
    "if len(glob.glob(f'{train_path}/*/*')) < len(dats_pos):\n",
    "    process_data(\n",
    "        dats=dats_pos, \n",
    "        msk=msk_pos,   \n",
    "        path_root=train_path, \n",
    "        path_modifier='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
