{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGELOG\n",
    "\n",
    "v0.3\n",
    "- hold out and external testing\n",
    "\n",
    "v0.2 11/1/2023\n",
    "- load each shard from data raw one by one instead of loading it all together into one dataset and then using dataset.skip.take\n",
    "\n",
    "v0.1 10/26/2023\n",
    "- try not sharding because it keeps crashing and changing the size of the shard doesn't matter\n",
    "\n",
    "v0.0 10/27/2023\n",
    "- A lot of patches are all black (from padding with 0's) or have mostly black and some white (background of slide)\n",
    "- Use filter_data to crudely get rid of as many as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2023-11-19 04:20:09 ] CUDA_VISIBLE_DEVICES automatically set to: 3           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()\n",
    "\n",
    "import glob, numpy as np, pandas as pd, tensorflow as tf, matplotlib.pyplot as plt, skimage.io, os, gc\n",
    "from tensorflow.keras import Input, Model, models, layers, optimizers, losses, callbacks, utils\n",
    "from pathlib import Path\n",
    "from jarvis.utils.display import imshow\n",
    "from PIL import Image\n",
    "from skimage.transform import rescale, resize\n",
    "from histomicstk.preprocessing.augmentation import rgb_perturb_stain_concentration\n",
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "import sys  \n",
    "sys.path.append('/home/jjlou/Jerry/jerry_packages')\n",
    "from jerry_utils import restart_kernel, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/jjlou/Jerry/wsi-arterio/vessel_detection_and_rough_segmentation/data_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(dataset=None):\n",
    "    dats = []\n",
    "    masks = []\n",
    "    for d, m in dataset:\n",
    "        rgb_mean = tf.math.reduce_mean(d)\n",
    "        if (rgb_mean > 210) or (rgb_mean < 65) or (rgb_mean == None):\n",
    "            continue\n",
    "        dats.append(d)\n",
    "        masks.append(m)\n",
    "    \n",
    "    return tf.data.Dataset.from_tensor_slices((dats, masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(load=None, save_path=None):\n",
    "    shards_path = sorted(glob.glob(f'{load}/*/*'))\n",
    "    for s in shards_path:\n",
    "        ID = s.split('/')[-2]\n",
    "        shard_num = s.split('/')[-1]\n",
    "        save_file = f'{save_path}/{ID}/{shard_num}'\n",
    "        if not glob.glob(f'{save_file}/*/*/*.snapshot'):\n",
    "            assert not glob.glob(f'{save_file}/*/*.shard'), f'{save_file} did not save'\n",
    "            shard = tf.data.Dataset.load(s)\n",
    "            shard = filter_data(shard)\n",
    "            shard.save(save_file)\n",
    "            restart_kernel()\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = f'{root}/train'\n",
    "train_save = f'{root}/train_filtered'\n",
    "\n",
    "if len(glob.glob(f'{train_save}/*/*')) < len(glob.glob(f'{train_load}/*/*')):\n",
    "    process_data(load=train_load, save_path=train_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_load = f'{root}/hold_out'\n",
    "hold_save = f'{root}/hold_out_filtered'\n",
    "\n",
    "if len(glob.glob(f'{hold_save}/*/*')) < len(glob.glob(f'{hold_load}/*/*')):\n",
    "    process_data(load=hold_load, save_path=hold_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_load = f'{root}/external'\n",
    "external_save = f'{root}/external_filtered'\n",
    "\n",
    "if len(glob.glob(f'{external_save}/*/*')) < len(glob.glob(f'{external_load}/*/*')):\n",
    "    process_data(load=external_load, save_path=external_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
