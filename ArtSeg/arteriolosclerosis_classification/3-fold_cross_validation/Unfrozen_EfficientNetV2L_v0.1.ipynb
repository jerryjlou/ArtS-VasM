{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGELOG\n",
    "\n",
    "v0.1 11/6/2023\n",
    "- add one layer to dense layers\n",
    "- make l5 and l6 the widest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2023-12-18 18:13:07 ] CUDA_VISIBLE_DEVICES already manually set to: 2        \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()\n",
    "\n",
    "import numpy as np, pandas as pd, tensorflow as tf, os, datetime\n",
    "from tensorflow.keras import Input, Model, layers, optimizers, losses, callbacks, utils\n",
    "from IPython.display import clear_output, HTML, Javascript, display\n",
    "\n",
    "import sys  \n",
    "sys.path.append('/home/jjlou/Jerry/jerry_packages')\n",
    "from jerry_utils import restart_kernel, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Unfrozen_EfficientNetV2L_v0.1'\n",
    "root = '/home/jjlou/Jerry/wsi-arterio/arteriosclerotic_vessel_detection_and_fine_segmentation/Arteriolosclerosis_classification/data'\n",
    "batch_size = 3\n",
    "epochs = 300\n",
    "learning_rate = 1e-3\n",
    "learning_ratio = 0.99\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid0 = ['D-436','D-870', 'D-343']\n",
    "Valid1 = ['D-297', 'D-916', 'UCI-15-12']\n",
    "Valid2 = ['D-322', 'D-562']\n",
    "\n",
    "Valid = [Valid0, Valid1, Valid2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.numpy_function creates output with unknown shape.. so need to reshape it\n",
    "def reshape(image, labels):\n",
    "    labels = tf.reshape(labels, [1,])\n",
    "    return tf.cast(image, 'uint8'), tf.cast(labels, 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Unfrozen_EfficientNetV2L ####\n",
    "\n",
    "def prepare_model(shape=(512, 512, 3)):\n",
    "    \n",
    "    # --- Transfer learning\n",
    "    base_model = tf.keras.applications.EfficientNetV2L(input_shape=shape, include_top=False)\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Use the activations of these layers\n",
    "    layer_names = [\n",
    "        'block1d_add',               # 256x256\n",
    "        'block2g_add',               # 128x128, layer 120\n",
    "        'block4a_expand_activation', # 64x64\n",
    "        'block6a_expand_activation', # 32x32, layer 551\n",
    "        'top_activation'             # 16x16\n",
    "    ]\n",
    "    \n",
    "    #Total 1028 layers, layer 551 corresponds to layer_names[3] so freeze the first 4 layers\n",
    "    fine_tune_at = 551 \n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "    \n",
    "    # --- Dr. Chang's base setup\n",
    "    kwargs = {    \n",
    "        'kernel_size':(3,3), \n",
    "        'padding':'same',\n",
    "        'kernel_initializer':'he_normal'}\n",
    "    \n",
    "    # --- Define functions\n",
    "    conv = lambda x, filters, strides=1, k=(3,3), r=1 : layers.SeparableConv2D(\n",
    "        filters=filters,\n",
    "        strides=strides,\n",
    "        dilation_rate=r,\n",
    "        kernel_size=k,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    tran = lambda x, filters : layers.Conv2DTranspose(\n",
    "        filters=filters,\n",
    "        strides=(2, 2),\n",
    "        **kwargs)(x)\n",
    "\n",
    "    norm = lambda x : layers.BatchNormalization()(x)\n",
    "    relu = lambda x : layers.LeakyReLU()(x)\n",
    "    \n",
    "    conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "    conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))\n",
    "    \n",
    "    tran2 = lambda filters, x : relu(norm(tran(x, filters)))\n",
    "    \n",
    "    concat = lambda x, y : layers.Concatenate()([x,y])\n",
    "    \n",
    "    # --- Create model\n",
    "    inputs = tf.keras.layers.Input(shape=shape, dtype='float32')\n",
    "    down = down_stack(inputs) # transfer layers from pre-trained model\n",
    "    \n",
    "    # Encoder\n",
    "    l0 = conv1(8, inputs)\n",
    "    l1 = conv1(16,concat(down[0],conv2(16, l0)))\n",
    "    l2 = conv1(32,concat(down[1],conv2(32, l1)))\n",
    "    l3 = conv1(48,concat(down[2],conv2(48, l2)))\n",
    "    l4 = conv1(96,concat(down[3],conv2(96, l3)))\n",
    "    l5 = conv1(64,concat(down[4],conv2(64, l4)))\n",
    "    l6 = conv1(72,conv2(72,l5))\n",
    "    l7 = conv1(96,conv2(96,l6))\n",
    "    \n",
    "    # Flatten\n",
    "    f0 = tf.keras.layers.Flatten(input_shape=(4, 4))(l7)\n",
    "    f1 = tf.keras.layers.Dense(32, activation='gelu')(f0)\n",
    "    f2 = tf.keras.layers.Dense(8, activation='gelu')(f1)\n",
    "\n",
    "    # --- Create logits\n",
    "    logits = tf.keras.layers.Dense(2)(f2)\n",
    "\n",
    "    # --- Create model\n",
    "    model = Model(inputs=inputs, outputs=logits) \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in Valid:\n",
    "    v_path = f\"{root}/K{Valid.index(v)}\"\n",
    "    train_path = f\"{v_path}/Train_K{Valid.index(v)}_Color.BasicMorph.Aug\"\n",
    "    valid_path = f\"{v_path}/Valid_K{Valid.index(v)}_raw\"\n",
    "    model_path = f'{v_path}/models/{name}_Color.BasicMorph.Aug_K{Valid.index(v)}.hdf5'\n",
    "    history_path = f'{v_path}/models/{name}_Color.BasicMorph.Aug_K{Valid.index(v)}.csv'\n",
    "    \n",
    "    if not os.path.exists(f'{v_path}/models'):\n",
    "        os.mkdir(f'{v_path}/models')\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        continue \n",
    "    else: \n",
    "        train = load_dataset(train_path)\n",
    "        valid = load_dataset(valid_path)\n",
    "\n",
    "        train = train.shuffle(train.cardinality()).map(lambda i,m: reshape(i,m), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        valid = valid.shuffle(valid.cardinality()).batch(1)\n",
    "\n",
    "        model = prepare_model()\n",
    "\n",
    "        lr_scheduler = callbacks.LearningRateScheduler(lambda epoch, lr : lr * learning_ratio)\n",
    "\n",
    "        # --- Compile model\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=loss,\n",
    "            metrics=metrics)\n",
    "\n",
    "        # --- Train\n",
    "        model_history = model.fit(\n",
    "            x=train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=valid,\n",
    "            callbacks=[lr_scheduler])\n",
    "\n",
    "        history = pd.DataFrame.from_dict(model_history.history)\n",
    "        history.to_csv(history_path)\n",
    "        \n",
    "        model.save(model_path)\n",
    "        \n",
    "        restart_kernel()\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
